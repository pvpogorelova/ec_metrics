install.packages("tidyverse")
install.packages("sjPlot")
install.packages("car")
install.packages("rio")

library(tidyverse) # манипуляции с данными и построение графиков
library(sjPlot) # красивые графики для линейных моделей
library(rio) # импорт/экспорт данных
library(car) # тестирование гипотез

# Импортируем данные.
data = import("/Users/polinapogorelova/Desktop/econ_metrics/dataflats.xlsx")

# Исследуем датасет и ценах на квартиры в Москве.
head(data)

# Переименуем столбцы с «неговорящими» названиями
data = rename(data, n = A, price = B)

# Сначала посмотрим на описательные статистики переменных.
summary(data) # для всех переменных сразу
summary(data$totsp) # для отдельной переменной
mean(data$totsp)
sd(data$totsp)

# И уберем строчки, в которых хотя бы один элемент пустой.
data = na.omit(data)

# Оценим параметры модели для стоимости 1 кв м квартиры. Сначала создадим такую переменную.
data = mutate(data, price_sq = price/totsp)

# Оценим первую модель, включающю две объясняющие переменные, и проинтерпретируем коэффициенты
ols_1 = lm(price_sq ~ livesp + dist, data = data)
summary(ols_1)

# Теперь оценим модель, в которую добавим еще одну переменню в правую часть - metrdist
ols_2 = lm(price_sq ~ livesp + dist + metrdist, data = data)
summary(ols_2)

# Вызовом одной функции получаем кучу полезных графиков :)
# Можем визуально оценить наличие гетероскедастичности, нормальность распределения остатков, наличие выбросов.
# Без дополнительных указаний функция построит 4 графика – по одному друг за другом.
# Мы для красоты c помощью функции `par` будем выводить по два графика :)

par(mfrow = c(2,2))
plot(ols_1)

# График **«Residuals vs Fitted»** помогает уловить возможные нелинейные зависимости между регрессором и объясняемой переменной.
# В «хорошем» случае мы ждем картинку с остатками, равномерно рассеянными вдоль горизонтальной прямой.

# График **«Normal Q–Q»** позволяет визуально оценить нормальность распределения остатков.
# Эталоном здесь является пунктирная прямая.

# График **«Scale – Location»** дает возможность «на глаз» оценить равную дисперсию остатков регресии и проверить наличие гетероскедастичности.

# График **«Residuals vs Leverage»** помогает выявить «влиятельные наблюдения» с высоким «воздействием» (high leverage).
# Это такие наблюдения, которые имеют нетипичные для выборки значения, но исключение которых может значительно повлиять на оценки коэффициентов модели.


# Получим предсказания модели для обучаемой выборки.
data = mutate(data, fitval = fitted(ols_1))

# Теперь выведем прогноз модели для 10 новых наблюдений (которые сами же и сгенерируем).
# Будем считать, что новые наблюдения распределены нормально с заданными математическими ожиданиями и стандартными отклонениями.

set.seed(7)
new_data = tibble(livesp = rnorm(10, mean = 40, sd = 5),
                  dist = rnorm(10, 10, 2),
                  metrdist = rnorm(10, 5, 2))
yhat_1 = predict(ols_1, newdata = new_data)
yhat_2 = predict(ols_2, newdata = new_data)

new_data = mutate(new_data, y_fit_1 = yhat_1, y_fit_2 = yhat_2)
